{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Could not load the module from examples/Water.py.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 26\u001b[0m\n\u001b[1;32m     24\u001b[0m spec \u001b[38;5;241m=\u001b[39m importlib\u001b[38;5;241m.\u001b[39mutil\u001b[38;5;241m.\u001b[39mspec_from_file_location(FILE_PATH)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 26\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not load the module from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mFILE_PATH\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     28\u001b[0m module \u001b[38;5;241m=\u001b[39m importlib\u001b[38;5;241m.\u001b[39mutil\u001b[38;5;241m.\u001b[39mmodule_from_spec(spec)\n\u001b[1;32m     29\u001b[0m spec\u001b[38;5;241m.\u001b[39mloader\u001b[38;5;241m.\u001b[39mexec_module(module)\n",
      "\u001b[0;31mImportError\u001b[0m: Could not load the module from examples/Water.py."
     ]
    }
   ],
   "source": [
    "import openturns as ot\n",
    "import importlib.util\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "from matplotlib import pylab as plt\n",
    "import openturns.viewer as otv\n",
    "\n",
    "# Define constants\n",
    "MODULE_NAME = \"FloodModel\"\n",
    "FILE_PATH = \"examples/Water.py\"\n",
    "OUTPUT_DIR = \"results\"\n",
    "OUTPUT_EXPECTATION_CSV = os.path.join(OUTPUT_DIR, \"expectation_convergence.csv\")\n",
    "OUTPUT_GRID_CSV = os.path.join(OUTPUT_DIR, \"grid.csv\")\n",
    "OUTPUT_FIRST_ORDER_SOBOL_CSV = os.path.join(OUTPUT_DIR, \"first_order_sobol_indices.csv\")\n",
    "OUTPUT_TOTAL_ORDER_SOBOL_CSV = os.path.join(OUTPUT_DIR, \"total_order_sobol_indices.csv\")\n",
    "\n",
    "# Ensure output directory exists\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Load the flood model\n",
    "if not os.path.exists(FILE_PATH):\n",
    "    raise FileNotFoundError(f\"File {FILE_PATH} does not exist.\")\n",
    "\n",
    "spec = importlib.util.spec_from_file_location(MODULE_NAME, FILE_PATH)\n",
    "if spec is None:\n",
    "    raise ImportError(f\"Could not load the module from {FILE_PATH}.\")\n",
    "\n",
    "module = importlib.util.module_from_spec(spec)\n",
    "sys.modules[MODULE_NAME] = module\n",
    "spec.loader.exec_module(module)\n",
    "\n",
    "function_of_interest, problem = module.model, module.problem\n",
    "\n",
    "# Create distributions\n",
    "distributions = ot.DistributionCollection()\n",
    "for dist_info in problem['distributions']:\n",
    "    dist_type = dist_info['type']\n",
    "    params = dist_info['params']\n",
    "    if dist_type == 'Uniform':\n",
    "        distributions.add(ot.Uniform(*params))\n",
    "    elif dist_type == 'Normal':\n",
    "        distributions.add(ot.Normal(*params))\n",
    "    elif dist_type == 'LogNormalMuSigma':\n",
    "        distributions.add(ot.ParametrizedDistribution(ot.LogNormalMuSigma(*params)))\n",
    "    elif dist_type == 'LogNormal':\n",
    "        distributions.add(ot.LogNormal(*params))\n",
    "    elif dist_type == 'Beta':\n",
    "        distributions.add(ot.Beta(*params))\n",
    "    elif dist_type == 'Gumbel':\n",
    "        distributions.add(ot.Gumbel(*params))\n",
    "    elif dist_type == 'Triangular':\n",
    "        distributions.add(ot.Triangular(*params))\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported distribution type: {dist_type}\")\n",
    "\n",
    "distribution = ot.ComposedDistribution(distributions)\n",
    "input_names = problem['names']\n",
    "\n",
    "# Define the OpenTURNS model\n",
    "ot_model = ot.PythonFunction(problem['num_vars'], 1, function_of_interest)\n",
    "\n",
    "# Draw the function\n",
    "n = 10000\n",
    "sampleX = distribution.getSample(n)\n",
    "sampleY = ot_model(sampleX)\n",
    "\n",
    "# Save data used in plotXvsY to CSV\n",
    "sampleX.exportToCSVFile(os.path.join(OUTPUT_DIR, \"X.csv\"), \",\")\n",
    "sampleY.exportToCSVFile(os.path.join(OUTPUT_DIR, \"Y.csv\"), \",\")\n",
    "\n",
    "X = pd.read_csv(os.path.join(OUTPUT_DIR, 'X.csv'))\n",
    "Y = pd.read_csv(os.path.join(OUTPUT_DIR, 'Y.csv'))\n",
    "X.columns = problem['names']\n",
    "\n",
    "grid_df = pd.concat([Y, X], axis=1)\n",
    "grid_df.to_csv(OUTPUT_GRID_CSV, index=False)\n",
    "\n",
    "# Estimate the Sobol' indices\n",
    "size = 1000\n",
    "sie = ot.SobolIndicesExperiment(distribution, size)\n",
    "inputDesign = sie.generate()\n",
    "inputDesign.setDescription(input_names)\n",
    "outputDesign = ot_model(inputDesign)\n",
    "\n",
    "sensitivityAnalysis = ot.SaltelliSensitivityAlgorithm(inputDesign, outputDesign, size)\n",
    "\n",
    "\n",
    "graph = sensitivityAnalysis.draw()\n",
    "view = otv.View(graph)\n",
    "output_visual_dir = \"results_visual/\"\n",
    "plt.savefig(os.path.join(output_visual_dir, \"sobol_indices.png\"))\n",
    "\n",
    "# Create DataFrames for Sobol indices\n",
    "rows = str(sensitivityAnalysis.getFirstOrderIndicesInterval()).split('\\n')\n",
    "data = [tuple(map(float, row.strip('[]').split(','))) for row in rows]\n",
    "df = pd.DataFrame(data, columns=['Upper Bound', 'Lower Bound'])\n",
    "new_df = pd.DataFrame({'Sobol Index': list(map(float, str(sensitivityAnalysis.getFirstOrderIndices()).strip('[]').split(',')))})\n",
    "first_order_df = pd.concat([new_df, df], axis=1)\n",
    "\n",
    "rows = str(sensitivityAnalysis.getTotalOrderIndicesInterval()).split('\\n')\n",
    "data = [tuple(map(float, row.strip('[]').split(','))) for row in rows]\n",
    "df = pd.DataFrame(data, columns=['Upper Bound', 'Lower Bound'])\n",
    "new_df = pd.DataFrame({'Sobol Index': list(map(float, str(sensitivityAnalysis.getTotalOrderIndices()).strip('[]').split(',')))})\n",
    "total_order_df = pd.concat([new_df, df], axis=1)\n",
    "\n",
    "# Save Sobol indices to CSV\n",
    "first_order_df.to_csv(OUTPUT_FIRST_ORDER_SOBOL_CSV, index=False)\n",
    "total_order_df.to_csv(OUTPUT_TOTAL_ORDER_SOBOL_CSV, index=False)\n",
    "\n",
    "# Define the input distribution\n",
    "input_vector = ot.RandomVector(distribution)\n",
    "\n",
    "# The output vector is a CompositeRandomVector\n",
    "output_vector = ot.CompositeRandomVector(ot_model, input_vector)\n",
    "\n",
    "# Define the algorithm for expectation convergence\n",
    "algo = ot.ExpectationSimulationAlgorithm(output_vector)\n",
    "algo.setMaximumOuterSampling(8000)\n",
    "algo.setBlockSize(1)\n",
    "algo.setCoefficientOfVariationCriterionType(\"NONE\")\n",
    "\n",
    "# Run the algorithm and store the result\n",
    "algo.run()\n",
    "result = algo.getResult()\n",
    "\n",
    "# Draw the convergence history and save the convergence data to a CSV file\n",
    "graphConvergence = algo.drawExpectationConvergence()\n",
    "data = graphConvergence.getDrawable(0).getData()\n",
    "sample_sizes = data[:, 0]\n",
    "mean_estimates = data[:, 1]\n",
    "\n",
    "# Compute standard deviations for the mean estimates\n",
    "standard_deviations = result.getStandardDeviation()\n",
    "\n",
    "# Calculate confidence intervals\n",
    "z_value = 1.96  # For a 95% confidence interval\n",
    "lower_bounds = mean_estimates - z_value * standard_deviations\n",
    "upper_bounds = mean_estimates + z_value * standard_deviations\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"Sample Size\": [point[0] for point in sample_sizes],\n",
    "    \"Mean Estimate\": [point[0] for point in mean_estimates],\n",
    "    \"Lower Bound\": [point[0] for point in lower_bounds],\n",
    "    \"Upper Bound\": [point[0] for point in upper_bounds]\n",
    "})\n",
    "df.to_csv(OUTPUT_EXPECTATION_CSV, index=False)\n",
    "\n",
    "# Function to save correlation coefficients to CSV\n",
    "def save_correlation_to_csv(corr_data, input_names, method, file_path):\n",
    "    data = {\n",
    "        'Variable': f\"[{','.join(input_names)}]\",\n",
    "        'Correlation_Coefficient': list(corr_data)\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_csv(file_path, index=False)\n",
    "\n",
    "# Perform correlation analysis and save results to CSV\n",
    "corr_analysis = ot.CorrelationAnalysis(sampleX, sampleY)\n",
    "\n",
    "methods = {\n",
    "    \"PCC\": corr_analysis.computePCC,\n",
    "    \"PRCC\": corr_analysis.computePRCC,\n",
    "    \"SRC\": corr_analysis.computeSRC,\n",
    "    \"SRRC\": corr_analysis.computeSRRC,\n",
    "    \"Pearson\": corr_analysis.computePearsonCorrelation,\n",
    "    \"Spearman\": corr_analysis.computeSpearmanCorrelation,\n",
    "}\n",
    "\n",
    "for method, func in methods.items():\n",
    "    indices = func()\n",
    "    save_correlation_to_csv(indices, input_names, method, os.path.join(OUTPUT_DIR, f\"{method}_coefficients.csv\"))\n",
    "\n",
    "# Combine CSV files for correlation coefficients\n",
    "def combine_csv_files(input_dir, output_file):\n",
    "    combined_df = None\n",
    "    \n",
    "    for file in os.listdir(input_dir):\n",
    "        if file.endswith('_coefficients.csv'):\n",
    "            method = file.replace('_coefficients.csv', '')\n",
    "            df = pd.read_csv(os.path.join(input_dir, file))\n",
    "            df = df.rename(columns={'Correlation_Coefficient': method})\n",
    "            if combined_df is None:\n",
    "                combined_df = df\n",
    "            else:\n",
    "                combined_df[method] = df[method]\n",
    "    \n",
    "    combined_df.to_csv(output_file, index=False)\n",
    "\n",
    "combine_csv_files(OUTPUT_DIR, os.path.join(OUTPUT_DIR, 'combined_coefficients.csv'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "# Ensure the output directory exists\n",
    "output_visual_dir = \"results_visual\"\n",
    "os.makedirs(output_visual_dir, exist_ok=True)\n",
    "\n",
    "# Function to plot correlation coefficients\n",
    "def plot_correlation_coefficients():\n",
    "    # Load the data\n",
    "    df = pd.read_csv('results/combined_coefficients.csv')\n",
    "\n",
    "    # Extract the first 'Variable' entry and use it to create x-ticks\n",
    "    xticks = df['Variable'][0].strip('[]').replace(\"'\", \"\").split(',')\n",
    "\n",
    "    # Convert the 'Variable' column to a unique identifier (e.g., just use the index for simplicity)\n",
    "    df['Variable'] = df.index\n",
    "\n",
    "    # Set the 'Variable' column as the index\n",
    "    df.set_index('Variable', inplace=True)\n",
    "\n",
    "    # Plot the data\n",
    "    ax = df.plot(kind='bar', figsize=(12, 8))\n",
    "    plt.xlabel('Variable Group Index')\n",
    "    plt.ylabel('Correlation Coefficient')\n",
    "    plt.title('Comparison of Correlation Coefficients Across Variables')\n",
    "    plt.legend(title='Method')\n",
    "\n",
    "    # Manually set the x-tick labels\n",
    "    ax.set_xticklabels(xticks, rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save the plot\n",
    "    plt.savefig(os.path.join(output_visual_dir, \"correlation_coefficients.png\"))\n",
    "    plt.close()\n",
    "\n",
    "# Function to plot expectation convergence\n",
    "def plot_expectation_convergence():\n",
    "    # Load the CSV file\n",
    "    csv_file = \"results/expectation_convergence.csv\"\n",
    "    data = pd.read_csv(csv_file)\n",
    "\n",
    "    # Plot the data\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    # Plot the mean estimates\n",
    "    plt.plot(data['Sample Size'], data['Mean Estimate'], label='Mean Estimate', color='blue')\n",
    "\n",
    "    # Plot the confidence intervals\n",
    "    plt.fill_between(np.array(data['Sample Size'], dtype=float), np.array(data['Lower Bound'], dtype=float), np.array(data['Upper Bound'], dtype=float), color='blue', alpha=0.2, label='95% Confidence Interval')\n",
    "\n",
    "    # Adding titles and labels\n",
    "    plt.title('Mean Estimate Convergence with Confidence Intervals')\n",
    "    plt.xlabel('Sample Size')\n",
    "    plt.ylabel('Mean Estimate')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Save the plot\n",
    "    output_image_path = os.path.join(output_visual_dir, \"mean_estimate_convergence_plot.png\")\n",
    "    plt.savefig(output_image_path)\n",
    "    plt.close()\n",
    "\n",
    "# Function to plot grid data\n",
    "def plot_grid_data():\n",
    "    # Load the CSV file\n",
    "    csv_file = 'results/grid.csv'\n",
    "    df = pd.read_csv(csv_file)\n",
    "\n",
    "    # Extract the columns\n",
    "    y = df['y0']\n",
    "    X = df.drop(columns=['y0'])\n",
    "\n",
    "    # Get the column names\n",
    "    X_names = X.columns\n",
    "\n",
    "    # Define the dimensions\n",
    "    dimX = X.shape[1]\n",
    "\n",
    "    # Create a grid of plots\n",
    "    fig, axes = plt.subplots(1, dimX, figsize=(15, 5))\n",
    "\n",
    "    # Plot each subplot\n",
    "    for j in range(dimX):\n",
    "        ax = axes[j] if dimX > 1 else axes\n",
    "        ax.scatter(X.iloc[:, j], y, alpha=0.5, s=5)\n",
    "        ax.set_xlabel(X_names[j], fontsize=12, fontweight='bold')\n",
    "        ax.tick_params(axis='x', rotation=90)  # Rotate x-ticks vertically\n",
    "        if j == 0:\n",
    "            ax.set_ylabel('y0')\n",
    "        else:\n",
    "            ax.set_ylabel(\"\")\n",
    "        ax.xaxis.set_major_formatter(ticker.ScalarFormatter(useMathText=True))\n",
    "        ax.ticklabel_format(style='sci', axis='x', scilimits=(0, 0))\n",
    "\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save the plot\n",
    "    plt.savefig(os.path.join(output_visual_dir, \"grid_plot.png\"))\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "\n",
    "# Generate all plots\n",
    "plot_correlation_coefficients()\n",
    "plot_expectation_convergence()\n",
    "plot_grid_data()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
